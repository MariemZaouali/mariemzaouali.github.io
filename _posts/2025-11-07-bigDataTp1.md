---
layout: post
title: TP1 Mise en place d'un traitement en lots 
subtitle: Premier TP
tags: [Big Data, Hadoop, Java, YARN, MapReduce]
author: Mariem ZAOUALI
---

# TP1 : Mise en place d'un traitement en lots : Hadoop, MapReduce et YARN

>**Objectifs du TP :**
> Au terme de ce TP, vous serez capable de :
> - Configurer un cluster avec un Name Node et des Data Nodes
> - Réaliser un programme de Map Reduce sur un fichier avec Hadoop

## Manipulation 1
Dans cette première manipumation, vous allez préparer votre environnement sur vos machines virtuelles. 
Pour ce faire, créez tout d'abord un répertoire `lab1` où vous allez créer votre fichier `docker-compose.yml`
dont le contenu est le suivant:

```yml
version: "3.3"

networks:
  net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/24
     
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      - net

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - net
  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    ports:
      - "8088:8088"
    networks:
      - net

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    networks:
      - net
  
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks:
      - net
  
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
```
et créez également le fichier de configuration `hadoop.env` dont le contenu est le suivant:
```yml
HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore-postgresql/metastore
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive
HIVE_SITE_CONF_datanucleus_autoCreateSchema=false
HIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false


CORE_CONF_fs_defaultFS=hdfs://namenode:9000
CORE_CONF_hadoop_http_staticuser_user=root
CORE_CONF_hadoop_proxyuser_hue_hosts=*
CORE_CONF_hadoop_proxyuser_hue_groups=*
CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec

HDFS_CONF_dfs_webhdfs_enabled=true
HDFS_CONF_dfs_permissions_enabled=false
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false

YARN_CONF_yarn_log___aggregation___enable=true
YARN_CONF_yarn_log_server_url=http://historyserver:8188/applicationhistory/logs/
YARN_CONF_yarn_resourcemanager_recovery_enabled=true
YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4
YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true
YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031
YARN_CONF_yarn_timeline___service_enabled=true
YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
YARN_CONF_yarn_timeline___service_hostname=historyserver
YARN_CONF_mapreduce_map_output_compress=true
YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec
YARN_CONF_yarn_nodemanager_resource_memory___mb=16384
YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle

MAPRED_CONF_mapreduce_framework_name=yarn
MAPRED_CONF_mapred_child_java_opts=-Xmx4096m
MAPRED_CONF_mapreduce_map_memory_mb=4096
MAPRED_CONF_mapreduce_reduce_memory_mb=8192
MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072m
MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144m
```

Lancez le réseau de containers en lançant la commande suivante:
```cmd
docker-compose up -d
```

Vous devez avoir cet affichage montrant que votre réseau de contenainers a été bien créé:



On va travailler avec le fichier `purchases.txt` (à télécharger [github du cours Udacity]([URL](https://github.com/juandecarrion/udacity-hadoop-course/blob/master/testdata/purchases.txt))). Mettez le fichier téléchargé dans le même répertoire que  Pour ce faire exécutez la commande suivante pour créer un répertoire sous le nom de input :
```cmd
  hadoop fs -mkdir -p input
```
Ensuite, déplacez le fichier **purchases.txt** vers le répertoire input.
```cmd
 sudo docker exec -it namenode hadoop fs –put purchases.txt input
```
Vérifiez l'existence de ce fichier dans votre HDFS:
```cmd
  hadoop fs –ls input
```
Lancez la commande tail suivante pour avoir l’affichage des dernières lignes du fichier purchases.txt :
```cmd
  hadoop fs -tail input/purchases.txt
```

## Manipulation 2

Dans cette manipulation, on va réaliser un job Map-Reduce. Un Job Map-Reduce se compose principalement de deux types de programmes : 
- **Mappers** : permettent d’extraire les données nécessaires sous forme de clef/valeur, pour pouvoir ensuite les trier selon la clef
-	**Reducers** : prennent un ensemble de données triées selon leur clef, et effectuent le traitement nécessaire sur ces données (somme, moyenne, total...)

Nous testerons un exemple de MapReduce qui va compter les mots dans le fichier purchases.txt. Afin de simplifier ce test de démarrage, je vous invite à cloner une repository de mon compte Github à l’aide de Git en suivant les étapes suivantes :

|L'instruction    | L'illustration      |
|-----------------|---------------------|
| Ouvrir Intellij Idea et cliquez sur « Get from VCS »  | ![image](https://github.com/user-attachments/assets/1a884dfe-a21a-4d7c-b3c9-059f68afcc5c) |
| Rendez-vous à https://github.com/MariemZaouali/enit_tp1_wordcount Et récupérez le lien pour cloner le projet | ![image](https://github.com/user-attachments/assets/897accce-df43-49b2-9a65-f1c4414a218a)|
| Copier le lien et appuyer sur clone. |![image](https://github.com/user-attachments/assets/dd437abd-b9d0-4855-ac2c-1fabdffbf164)|
|Ouvrir le fichier main WordCount et appuyer sur « Current File » puis « Run Configuration ». Choisissez un jdk8 et mettre le chemin vers votre classe main (rectangle jaune), mettez dans le champs Program Arguments : src/main/resources/input/file.txt src/main/resources/output|    ![image](https://github.com/user-attachments/assets/dcabfca3-bbf1-4430-86bf-a1d8bf97ce78)|
| Le fichier à analyser se trouve sous le dossier ressources/input/file.txt. On va tester notre code sur le local sur un fichier léger avant d’aller lancer un job sur le cluster.|![image](https://github.com/user-attachments/assets/bee5c1c5-7366-4f7d-aa8e-e4b53a16e300)|
|Si votre code est encore en rouge, c’est normal nous devons télécharger les dépendances (librairies requises) du projet. |![image](https://github.com/user-attachments/assets/87586b89-9539-48aa-9694-a99103c53ae0)|
|Appuyer sur le menu maven à droite puis sur le bouton de refresh pour lancer le téléchargement des dépendances, puis sur « install ». Le résultat est de vous générer le fichier .jar |![image](https://github.com/user-attachments/assets/3b571985-3e1f-4192-800d-014968af32af)|
|Tout va bien maintenant, allez au main et exécutez ! A la fin de l'exécution un fichier **jar** sera créé.|![image](https://github.com/user-attachments/assets/59880520-7714-490a-a8d2-b6360614201a)|

Un répertoire **output** sera créé dans le répertoire resources, contenant les fichiers résultants de l'exécution du programme **wordcount**. Ouvrez ces fichiers. Vous pouvez changer le contenu du fichier `file.txt` pour voir l'effet du programme Wordcount!

Vous avez deux modes pour passer à l'exécution sur votre machine virtuelle sur le cloud ou sur le cluster.
### Exécution sur la machine virtuelle du cloud
Rendez-vous à l'emplacement de ce jar qui ce trouve dans le répertoire target de votre projet. Une fois bien positionné sur le répertoire en question, vous lancez la commande suivante:

```cmd
hadoop jar Wordcount2-0.jar tn.enit.tp1.WordCount input output
```
Après avoir terminé, visualisez le résultat :
```cmd
hadoop fs -tail output/part-r-00000
```
Vous pouvez accéder à l’interface du namenode via http://localhost:8088.
![image](https://github.com/user-attachments/assets/fe9aa994-f685-4644-8d4a-34a5f903ac17)

Il est également possible de voir le comportement des noeuds esclaves, en allant à l'adresse: http://localhost:8041 pour slave1, et http://localhost:8042 pour slave2. 

### Exécution avec le réseau de docker-compose
En accédant à n'importe quel conteneur (container) vous êtes capables de lancer les commandes de **hdfs** et avoir le même résultat. Mais avant de lancer la commande de **hdfs**, nous allons charger le fichier `purchases.txt` sur un des containers puis nous allons le mettre sur **hdfs**. Donc, la première étape consiste à se placer sous le répertoire où se trouve le fichier `purchases.txt`:
```cmd
sudo docker cp purchases.txt namenode:/purchases.txt
```
Maintenant, nous chargeons ce fichier, qui se trouve maintenant dans le container **namenode**, sur **hdfs**:
```cmd
sudo docker exec -it namenode hdfs dfs -mkdir -p input
```
ensuite:
```cmd
sudo docker exec -it namenode hdfs dfs -put purchases.txt input/purchases.txt
```
Ensuite, nous chargeons le fichier jar `Wordcount2-0.jar`, généré par votre application, sur le même container en se plaçant sous le dossier **target** qui se trouve en local (hors des containers, sur votre machine) et ce en tapant:
```cmd
sudo docker cp Wordcount2-0.jar namenode:/Wordcount2-0.jar
```
Enfin, lancez MapReduce en tapant:

```cmd
sudo docker exec -it namenode hadoop jar Wordcount2-0.jar tn.enit.tp1.WordCount input output
```

Après avoir terminé, visualisez le résultat :
```cmd
sudo docker exec -it namenode hadoop fs -tail output/part-r-00000
```

## Manipulation 3
On va travailler sur d’autres données autre que `purchases.txt`. Rendez-vous au site http://archive.ics.uci.edu et chercher la dataset « census income ». 
1.	Ecrire un programme mapReduce qui vous permet d’afficher la moyenne d’heures de travail par état civil (marital status) vu en cours. Utiliser le combiner dans votre traitement (pensez à utiliser NumPair).
2.	Proposer un traitement mapReduce qui explique si cette population est instruite (choisissez les champs et l’opération qui convient)
3.	[Projet, travail d'équipe] Proposer un traitement MapReduce sur des données d'un domaine de votre choix.



## Manipulation 4 (Optionnel)

Il est demandé de passer d'une architecture namenode + datanode à une architecture contenant namenode + 2 datanodes . Vous devez donc passer par la configuration du fichier `hdfs-site.xml` ainsi que la création des espaces pour chaque datanode. Donner les étapes nécessaires pour le faire.
